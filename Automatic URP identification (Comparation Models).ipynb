{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic URP Identification (Comparation Models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we implemmented and tested some Machine and Deep learning models to compare with C-BLSTM. We use te <b>Sklearn</b>, <b>Keras</b> and <b>Tensorflow</b> <i>Python libraries</i> for this work. We use Support Vector Machine (<i>SVM</i>), Decision Trees, Multi-Layer Perceptron (<i>MLP</i>), Nave Bayes, Long Short-Term Memory (<i>LSTM</i>), Bidirectional LSTM (<i>BLSTM</i>) and Convolutional Neural Networks (<i>CNN</i>). For each model, <b>f1-score</b>, <b>precision</b> and <b>recall</b> are measured and apresented."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from keras.preprocessing import text, sequence\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, AveragePooling1D\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM, Bidirectional, TimeDistributed\n",
    "from keras.layers import Conv1D, MaxPooling1D, GlobalMaxPooling1D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naoPru_Clean.xlsx\n",
      "Pru_Clean.xlsx\n",
      "twitter_Clean.xlsx\n"
     ]
    }
   ],
   "source": [
    "mypath = 'Stem Data'\n",
    "\n",
    "base = pd.DataFrame()\n",
    "for file in listdir(mypath):\n",
    "    print(file)\n",
    "    new_entries_base = pd.read_excel(mypath+'/'+file)\n",
    "    base = base.append(new_entries_base,ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = base['Postagens'].values\n",
    "classes = [\"PRU\", \"NPRU\"]\n",
    "y = base[classes].values\n",
    "\n",
    "y_ml = []\n",
    "for i in range(len(y)):\n",
    "    if y[i][0] == 1 and y[i][1]==0:\n",
    "        y_ml.append(1)\n",
    "    else:\n",
    "        y_ml.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_x = pd.DataFrame()\n",
    "lista = []\n",
    "for c in x:\n",
    "    lista.append(word_tokenize(str(c)))\n",
    "new_x = lista"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 547,   8,\n",
       "         2, 212,  21,  10, 547, 882])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_features = 20000\n",
    "maxlen = 45\n",
    "tokenizer = text.Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(new_x))\n",
    "new_x = tokenizer.texts_to_sequences(new_x)\n",
    "X_comp = sequence.pad_sequences(new_x, maxlen=maxlen)\n",
    "X_comp[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dividing Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3093\n",
      "774\n"
     ]
    }
   ],
   "source": [
    "xTrain, xTest, yTrain, yTest = train_test_split(X_comp, y_ml, test_size=0.2, random_state=42)\n",
    "print(len(yTrain))\n",
    "print(len(yTest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traditional Machine Learning Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1000, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.0001, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = SVC(kernel= 'rbf', C = 1000, gamma = 0.0001)\n",
    "svm.fit(xTrain,yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.23      0.35       364\n",
      "          1       0.76      0.96      0.85       906\n",
      "\n",
      "avg / total       0.74      0.75      0.71      1270\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_svm = svm.predict(xTest)\n",
    "print(classification_report(yTest, y_svm.round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.752755905511811\n",
      "ROC Curve:  0.5974425684690585\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: ', accuracy_score(yTest, y_svm.round()))\n",
    "print('ROC Curve: ', roc_auc_score(yTest, y_svm.round()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(xTrain, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.63      0.67      0.65       364\n",
      "          1       0.86      0.84      0.85       906\n",
      "\n",
      "avg / total       0.80      0.79      0.80      1270\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_dt = dt.predict(xTest)\n",
    "print(classification_report(yTest, y_dt.round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.794488188976378\n",
      "ROC Curve:  0.7573502656284113\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: ', accuracy_score(yTest, y_dt.round()))\n",
    "print('ROC Curve: ', roc_auc_score(yTest, y_dt.round()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nv = GaussianNB()\n",
    "nv.fit(xTrain, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.29      0.99      0.44       364\n",
      "          1       0.00      0.00      0.00       906\n",
      "\n",
      "avg / total       0.08      0.29      0.13      1270\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_nv = nv.predict(xTest)\n",
    "print(classification_report(yTest, y_nv.round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.28503937007874014\n",
      "ROC Curve:  0.49725274725274726\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: ', accuracy_score(yTest, y_nv.round()))\n",
    "print('ROC Curve: ', roc_auc_score(yTest, y_nv.round()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', alpha=0.0001, batch_size='auto',\n",
       "       beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(250, 100), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(250,100, ), activation='logistic', solver='adam', max_iter=100)\n",
    "mlp.fit(xTrain, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.49      0.55      0.52       364\n",
      "          1       0.81      0.77      0.79       906\n",
      "\n",
      "avg / total       0.72      0.70      0.71      1270\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_mlp = mlp.predict(xTest)\n",
    "print(classification_report(yTest, y_mlp.round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7039370078740157\n",
      "ROC Curve:  0.6577274822307936\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: ', accuracy_score(yTest, y_mlp.round()))\n",
    "print('ROC Curve: ', roc_auc_score(yTest, y_mlp.round()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3093\n",
      "774\n"
     ]
    }
   ],
   "source": [
    "xTrain, xTest, yTrain, yTest = train_test_split(X_comp, y, test_size=0.2, random_state=42)\n",
    "print(len(yTrain))\n",
    "print(len(yTest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Long Short-Term Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 45, 128)           2560000   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 45, 64)            49408     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 45, 64)            0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 32)                12416     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 2,621,890\n",
      "Trainable params: 2,621,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm = Sequential()\n",
    "lstm.add(Embedding(max_features, 128, input_length=maxlen))\n",
    "lstm.add(LSTM(64, recurrent_dropout=0.2, return_sequences=True))\n",
    "lstm.add(Dropout(0.2))\n",
    "lstm.add(LSTM(32))\n",
    "lstm.add(Dropout(0.5))\n",
    "lstm.add(Dense(2,activation='softmax'))\n",
    "lstm.summary()\n",
    "lstm.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4569 samples, validate on 508 samples\n",
      "Epoch 1/5\n",
      " - 73s - loss: 0.4456 - acc: 0.7960 - val_loss: 0.3180 - val_acc: 0.8661\n",
      "Epoch 2/5\n",
      " - 59s - loss: 0.2512 - acc: 0.9076 - val_loss: 0.3100 - val_acc: 0.8780\n",
      "Epoch 3/5\n",
      " - 30s - loss: 0.1716 - acc: 0.9396 - val_loss: 0.4300 - val_acc: 0.8642\n",
      "Epoch 4/5\n",
      " - 30s - loss: 0.1326 - acc: 0.9567 - val_loss: 0.4440 - val_acc: 0.8622\n",
      "Epoch 5/5\n",
      " - 30s - loss: 0.0984 - acc: 0.9670 - val_loss: 0.4565 - val_acc: 0.8583\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.88      0.91       906\n",
      "          1       0.74      0.84      0.79       364\n",
      "\n",
      "avg / total       0.88      0.87      0.87      1270\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lstm.fit(xTrain, yTrain, batch_size=32, epochs=5, validation_split=0.1, verbose=2)\n",
    "y_lstm = lstm.predict(xTest)\n",
    "print(classification_report(yTest, y_lstm.round()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bidirectional Long Short-Term Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 45, 128)           2560000   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 45, 128)           98816     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 45, 128)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 64)                41216     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 2,700,162\n",
      "Trainable params: 2,700,162\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "blstm = Sequential()\n",
    "blstm.add(Embedding(max_features, 128, input_length=maxlen))\n",
    "blstm.add(Bidirectional(LSTM(64, recurrent_dropout=0.2, return_sequences=True)))\n",
    "blstm.add(Dropout(0.2))\n",
    "blstm.add(Bidirectional(LSTM(32)))\n",
    "blstm.add(Dropout(0.5))\n",
    "blstm.add(Dense(2,activation='softmax'))\n",
    "blstm.summary()\n",
    "blstm.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4569 samples, validate on 508 samples\n",
      "Epoch 1/5\n",
      " - 56s - loss: 0.4230 - acc: 0.8142 - val_loss: 0.2970 - val_acc: 0.8858\n",
      "Epoch 2/5\n",
      " - 52s - loss: 0.2313 - acc: 0.9160 - val_loss: 0.3220 - val_acc: 0.8720\n",
      "Epoch 3/5\n",
      " - 58s - loss: 0.1502 - acc: 0.9494 - val_loss: 0.3943 - val_acc: 0.8602\n",
      "Epoch 4/5\n",
      " - 54s - loss: 0.1041 - acc: 0.9672 - val_loss: 0.3867 - val_acc: 0.8898\n",
      "Epoch 5/5\n",
      " - 55s - loss: 0.0729 - acc: 0.9783 - val_loss: 0.4132 - val_acc: 0.8898\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.92      0.92       906\n",
      "          1       0.80      0.80      0.80       364\n",
      "\n",
      "avg / total       0.89      0.89      0.89      1270\n",
      "\n"
     ]
    }
   ],
   "source": [
    "blstm.fit(xTrain, yTrain, batch_size=32, epochs=5, validation_split=0.1, verbose=2)\n",
    "y_blstm = blstm.predict(xTest)\n",
    "print(classification_report(yTest, y_blstm.round()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 45, 50)            1000000   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 45, 50)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 43, 250)           37750     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 250)               62750     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 502       \n",
      "=================================================================\n",
      "Total params: 1,101,002\n",
      "Trainable params: 1,101,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_dims = 50\n",
    "filters = 250\n",
    "kernel_size = 3\n",
    "hidden_dims = 250\n",
    "\n",
    "cnn = Sequential()\n",
    "cnn.add(Embedding(max_features,embedding_dims,input_length=maxlen))\n",
    "cnn.add(Dropout(0.2))\n",
    "cnn.add(Conv1D(filters,kernel_size,padding='valid',activation='relu',strides=1))\n",
    "cnn.add(GlobalMaxPooling1D())\n",
    "cnn.add(Dense(hidden_dims, activation='relu'))\n",
    "cnn.add(Dropout(0.2))\n",
    "cnn.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "cnn.summary()\n",
    "cnn.compile(loss='binary_crossentropy', \n",
    "\t\t\t  optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2783 samples, validate on 310 samples\n",
      "Epoch 1/5\n"
     ]
    }
   ],
   "source": [
    "cnn.fit(xTrain, yTrain, batch_size=32, epochs=5, validation_split=0.1, verbose=2)\n",
    "y_cnn = cnn.predict(xTest)\n",
    "print(classification_report(yTest, y_cnn.round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pru = []\n",
    "for i in range(len(yTest)):\n",
    "    y_pru.append(yTest[i][1])\n",
    "import scikitplot as skplt\n",
    "skplt.metrics.plot_cumulative_gain(y_pru, y_cnn)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
